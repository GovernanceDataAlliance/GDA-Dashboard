---
published: true
layout: blog/post
date: "2015-12-14"
author: ""
image: ""
category: ""
tags: meeting_notes producers_workshop
title: Data Collection and Analysis Tools
---
Below are the notes from our second producers’ workshop. The session, co-led by the World Justice Project (WJP) and Freedom House (FH), focused on data collection and analysis tools.


Organizations presented and discusses their data collection and analysis tools

## I - Data Collection

**Vanessa on Freedom in the World (FH)**

**Process**

- An expert coder (external to Freedom House) code the events of the year in a given country
- These scores are presented at a rating review meeting with experts
- Score changes are done by consensus 
- The expert coder also produces a narrative report

**Strengths**

- It provides a simple assessment of the complex question of political rights, which we do not have clear quantitative indicators for
- The scale is from 0-7 will allows for easy for global comparisons

**Drawbacks** 

- The scale is from 0-7 - it’s a blunt tool
- Experts
	- Finding experts: it is challenging to find the right experts who can also write an “academic” narrative
	- Logistical challenges: we privilege in-country experts, which makes getting everyone to the US difficult.
	- Security challenges: in some places, those participating in the survey are seen as criticizing part of political system, and therefore face security issues. They often do not communicate with ease or come to the US

- Scoring system has become more complex and rigorous in the last 20 years, and FH would like to go back and recode previous years, but does not have the resources to do so.

**Joel on the Rule of Law Index (WJP)**

**Data collection tools:**

- Expert surveys and household surveys are the two sources of data
- The research is done in 53 countries
- In most countries, the household survey is carried out every other year
- The experts’ survey is carried out every year. 

**Experts’ survey:**

- It is taken by in-country experts (about 2,500 responses) through Survey Gizmo (in a few countries it is completed in a word document and faxed)
- The survey is only available in English, French, and Spanish, which creates gaps
- It is a longitudinal survey so you can compare results over time

**Household survey:**

- It is administered to 1,000 people in each of the country’s three largest cities 
- The survey, administered by polling companies, takes 3 months
- The questionnaire is administered in the local language (and in most countries via face-to-face interviews) 
Index strengths
- Two sources of data help get different perspectives (in some cases general population knows best, in others, experts do)
- Focusing on 3 cities only is cheaper (but doesn’t represent rural areas)

**Index challenges**

- Cost: Household surveys are very expensive [the cost for the survey varies by location, but it is for example 20-60K in the Middle East; and 90K in Afghanistan, the most expensive); around $1M per release 

- Experts survey: these are very time-consuming and done pro bono which makes it challenging to get experts to agree to do them and follow through
	- How do you incentivize participation of experts?
	- How do you vet experts and polling companies?


**Joe Spanjers on the Global Illicit Financial Flows Report (GFI)**

- The report looks at illicit flows out of developing countries 
- Unlike others in the Alliance, GFI’s data collection involves pulling data (government data vetted by the IMF) from online databases and playing with it
- Experts are consulted on the methodology but do not participate in the data collection and analysis
- Sometimes the numbers are quite surprising and/or governments complain, but GFI does not have the human and financial resources to check everything

**Joel of WJP – how to vet the data and how to deal with criticism is an important question and challenge**

**Nathaniel Heller on Global Integrity data (wearing a previous hat!)**

- There is always a selection bias when choosing experts
	- How do you minimize it and demonstrate that results are viable?
- Double blind peer review process can help catch huge problems 

**Elena on the Open Budget Survey (IBP)**

- For questions focused on the availability of documents, IBP can check answers
- For others that are harder to assess, peer reviewers help
- IBP also has a government reviewer
- More recently, IBP has shifted to one peer reviewer only, giving more money to a single (stronger) reviewer

**Juan (WJP)**

- Governments want to reverse engineer to increase their score
- For this reason, WJP created an index with four pillars (expert survey, general population survey, other quantitative data available + qualitative data collection, statistical analysis) which allow the identification and correction of errors 

**Nathaniel on Global Integrity data**

- Over time, GI reduced the number of peer reviewers and increased pay (as IBP did) and found that the quality of the reviews increased
- Unsurprisingly, money creates leverage 

**WJP**
- It can be difficult to retain experts from one year to the next

**Elena (IBP)**
- Good to strive to keep researchers and reviewers over time; this helps strengthen their expertise and reliability 

**WJP**

- The importance of reviewers depends on the type of data you are looking at

**Vanessa (FH)**

- Best to use different tools in conjunction with each other

**Preston IRM (OGP)**

- National experts panels help design the method; the panel consists of 10 experts in different areas of open government (for example government accountability; participation; access to information etc.) and with different regional expertise 
- Critiques of this method (especially from governments) focus on the bias born from the selection of the experts
- OGP sends draft reports to government points of contact and lead civil society group for review
	- The quality of government comments is improving over time (as they better understand the methodology for addressing comments)
	- The final report often ends up making both civil society and government mad

**Jesse on the Environmental Democracy Index (WRI)**

- It is WRI’s first index and was therefore a great learning opportunity 
- It evaluates the quality of the law
- The practice of the law indicators were not comprehensive so they were not included in the final score 
- Benchmarking was done using UNEP guidelines (“Bali Guidelines”) on principle 10
- Before EDI, WRI had assessments, but they were expensive and did not look at contextual factors, which made it hard to compare countries
- WRI disaggregated the guidelines into discrete indicators	
	- Does the law exist?
    - How strong are the clauses around timeliness, low-cost etc.?

**Data collection: **

- WRI contracted with 70 legal experts who scored indicators, using Indaba 
	- They had to provide the law and specific clause 
- Indicators then went to national reviewers; but it was not a double blind review
	- In future WRI may do double blind because there was high variability in the quality of reviews
- Then two stages of review at WRI, including a lawyer 
	- Scorers/reviewers did not always look at every relevant law
	- WRI ended up looking at every clause
- Any issue from the first or WRI reviewers were sent to initial scorer for a response
- Once the issue was addressed by initial scorer, the indicators were passed onto final WRI reviewer
- In future WRI wants an expert panel review approach similar to FH’s with like legal/regional etc. experts	
	- This year the resources were not available
- Cost: $1,000 for researcher [50-60 hours]; less for reviewer  
	- Can we make the scoring more efficient in future?
- Scores were sent to relevant government agencies (Ministry of Finance, Energy, etc.)
	- Mostly disagreements came with evidence to support claim 
- WRI is looking to form partnerships with academic institutes that can provide input on the methodology (to avoid survey)
- The next EDI will focus more on implementation
	- Still fundraising
- The index looks at objective criteria in the law
- Some questions that look at implementation are pretty straightforward (ex. is city air quality published online?)
	- Others not as straightforward (was there an environmental assessment for big projects? Was there participation? Etc.)
- Initial researchers
	- Credential lawyers in their country
	- Had experience in this type of law (administrative and environmental law)
	- WRI asked for nominations from Access Initiative members and worked through UNEP and other CSOs
	- Some people did it because cared about the project; the money was really low for work involved
	- Lawyers needed to be independent
- Reviewer could be from the government 
	- They were a mix of civil society, academia, judges, and in a couple of cases, public sector people
- It was helpful to have government reviewers for impact

**Jason McMann on Resource Governance Index (NRGI)**

- 1 researcher and 1 peer reviewer (in-country)
	- In-house research assistants
- It is a challenge to select people who are independent from both the government and mining companies 
- NRGI previously used Indaba, is now developing an in-house platform
- NRGI is considering adding a government reviewer starting in March

**Data collection tools**

- Abhinav - Organizations transitioning away from Indaba
- Vanessa – currently using web-based excel; looking at new options 
	- AmidaTech purchased Indaba and rebuilding it
- Elena – Indaba is still “on”
- Jason – NRGI is putting together a new tool that will (he thinks) be made open-source / available for all to use
	- Great for data-based questionnaire

**Elena - IBP**

- For questions that are not documents, we look at other data to try to triangulate (experts; newspaper articles)
- Languages: initially had English, French, and Spanish questionnaires (mostly use English); now IBP translates questionnaire in other languages for people to use as a reference


## II - Data Analysis

**Mohammed from WJP**

- Index has 500 variables 
- The bulk of the analysis involves editing data to fix weird or missing data
- The scores are between 0-1 (from least to most rule of law)
	- 8 factors  1 score
- Recently included changes over time   
- WJP goes through a data validation exercise – cross-checking with 3rd party sources
- Present analysis in form of an index in June, with country-specific reports in some cases
- Data on site so that people can interact with country and factor-level data

**Vanessa – FH** 

- Three ratings: Free, partly free, not free
- The report involves a basic analysis of changes over time
- FH would like to invest into this further, including with better data visualization 
- Lots of time currently spent on data entry – not analysis (a common issue across the group)

**Elena - IBP**

- 132 indicators; 102 countries
- IBP created a survey explorer which makes all responses available 
	- Answers are grouped by topic (ex. Public participation; strength of oversight)
	- People can play with data
	- The “calculator” tool allows users to see how score would change as you change answers
	- Users can see answers and comments, and examples
    - Users can see examples of how to score higher

**Mohammed: do you track use of the survey explorer?**

**Elena:**

- IBP tracks how many people click on the different products 

**Nathaniel:**

- the AidData report will help us figure out who is using/not using our data and how
- This should help inform decisions about how to invest 

**Joe Spanjerss**

 – GFI uses DataWrapper to do map

**Nathaniel:** 

- with the Alliance’s Data Dashboard, we will be able to visualize country-level scores (through cardo DB)
- Tableau software has mapping as well

**Mohammed - WJP**

- We try to incentivize the use and analysis of data by experts

**Abhinav - OGP **

- Also want to encourage people to use data – how do we incentive this?  

**Nathaniel:**

- R4D is working on a data dashboard around agriculture – to incentivize additional agriculture spending 
- For this and others, what is the causal chain that will help achieve objectives?
- Should Alliance look at successful cases, what happened?

**Jesse Worker, WRI**

- WRI did a basic analysis only as well because there was not enough time
- Researchers were very behind - how do we manage all the delays?

**Nathaniel ** on GI’s experience

Some options include:

- Staggering payments
- Setting multiple deadlines 
	- Submit first 10 questions early
	- This gives you the opportunity to test researchers and find new ones early on
- Providing a lot of pre-game training
- How do you streamline vetting process? Rolodex for the Alliance? 
	- Researchers care about their reputation

**All: never enough time for analysis**

**Nathaniel: **

- We could talk to companies such as Splunk; Google that do large scale data mining
- Should have a conversation with DataKind 
	- The company provides data scientists for free to non-profits

**Other matters**

- We should have a launch event early 2016 with Data Dashboard
	- Future of governance data collection?
- AidData meeting in early January



